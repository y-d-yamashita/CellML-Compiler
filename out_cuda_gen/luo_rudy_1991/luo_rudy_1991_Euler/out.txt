#include<stdio.h>
#include<math.h>
#include<cutil.h>
#include<cuda.h>
#define __DATA_NUM 32
#define __DATA_NUMX 32
#define __DATA_NUMY 1
#define __THREADS_X 256
#define __THREADS_Y 1
#define __THREADS_Z 1
#define __BLOCKS_X ( __DATA_NUM /  ( __THREADS_X * __THREADS_Y * __THREADS_Z ) ) 
#define __BLOCKS_Y 1


int main ( int argc , char** argv ) ;
__global__ void __init_kernel ( double* xi ) ;
__global__ void __calc_kernel ( double* xi , double* xo , double* x1 , double* x2 , double* k1 , double* y1 , double* z , double t , double d , double R ) ;

int main ( int argc , char** argv ) {

	double* __host_xi;
	double* __dev_xi;
	double* __host_xo;
	double* __dev_xo;
	double* __host_x1;
	double* __dev_x1;
	double* __host_x2;
	double* __dev_x2;
	double* __host_k1;
	double* __dev_k1;
	double* __host_y1;
	double* __dev_y1;
	double* __host_z;
	double* __dev_z;
	double t;
	double d = 0.010000;
	dim3 __block ( __THREADS_X , __THREADS_Y , __THREADS_Z ) ;
	dim3 __grid ( __BLOCKS_X , __BLOCKS_Y ) ;

	CUT_DEVICE_INIT ( argc , argv ) ; 
	__host_xi = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; ;
	__host_xo = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; ;
	__host_x1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; ;
	__host_x2 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; ;
	__host_k1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; ;
	__host_y1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 31 )  )  ) ; ;
	__host_z = (double*)malloc (  ( sizeof( double ) * 18 )  ) ; ;
	memset ( __host_xi , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	memset ( __host_xo , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	memset ( __host_x1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	memset ( __host_x2 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	memset ( __host_k1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	memset ( __host_y1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 31 )  )  ) ; 
	memset ( __host_z , 0 ,  ( sizeof( double ) * 18 )  ) ; 
	cudaMalloc ( ( void** ) &__dev_xi ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_xo ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x1 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x2 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_k1 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_y1 ,  ( sizeof( double ) *  ( __DATA_NUM * 31 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_z ,  ( sizeof( double ) * 18 )  ) ; 
	cudaMemcpy ( __dev_xi , __host_xi ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_xo , __host_xo ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x1 , __host_x1 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x2 , __host_x2 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_k1 , __host_k1 ,  ( sizeof( double ) *  ( __DATA_NUM * 8 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_y1 , __host_y1 ,  ( sizeof( double ) *  ( __DATA_NUM * 31 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_z , __host_z ,  ( sizeof( double ) * 18 )  , cudaMemcpyHostToDevice ) ; 
	__init_kernel <<< __grid , __block >>>  ( __dev_xi ) ; 
	for(t = 0.000000; ( t <= 400.000000 ) ;t =  ( t + d ) ){

		for(ix = 0; ( ix < __DATA_NUMX ) ;ix++){

			for(iy = 0; ( iy < __DATA_NUMY ) ;iy++){

				__calc_kernel <<< __grid , __block >>>  ( __dev_xi , __dev_xo , __dev_x1 , __dev_x2 , __dev_k1 , __dev_y1 , __dev_z , t , d ) ; 

			}


		}


	}

	free ( __host_xi ) ; 
	free ( __host_xo ) ; 
	free ( __host_x1 ) ; 
	free ( __host_x2 ) ; 
	free ( __host_k1 ) ; 
	free ( __host_y1 ) ; 
	free ( __host_z ) ; 
	cudaFree ( __dev_xi ) ; 
	cudaFree ( __dev_xo ) ; 
	cudaFree ( __dev_x1 ) ; 
	cudaFree ( __dev_x2 ) ; 
	cudaFree ( __dev_k1 ) ; 
	cudaFree ( __dev_y1 ) ; 
	cudaFree ( __dev_z ) ; 
	CUT_EXIT ( argc , argv ) ; 
}


__global__ void __init_kernel ( double* xi ) {

	const unsigned int __tmp_idx_x =  ( threadIdx.x +  ( blockDim.x * blockIdx.x )  ) ;
	const unsigned int __tmp_idx_y =  ( threadIdx.y +  ( blockDim.y * blockIdx.y )  ) ;
	const unsigned int __tmp_size_x =  ( blockDim.x * gridDim.x ) ;
	const unsigned int __tid =  ( __tmp_idx_x +  ( __tmp_idx_y * __tmp_size_x )  ) ;

}


__global__ void __calc_kernel ( double* xi , double* xo , double* x1 , double* x2 , double* k1 , double* y1 , double* z , double t , double d , double R ) {

	const unsigned int __tmp_idx_x =  ( threadIdx.x +  ( blockDim.x * blockIdx.x )  ) ;
	const unsigned int __tmp_idx_y =  ( threadIdx.y +  ( blockDim.y * blockIdx.y )  ) ;
	const unsigned int __tmp_size_x =  ( blockDim.x * gridDim.x ) ;
	const unsigned int __tid =  ( __tmp_idx_x +  ( __tmp_idx_y * __tmp_size_x )  ) ;
	double ym;

	ym = (__tmp_idx_y!=0)?(xi[ (0 * __DATA_NUM) + (__tmp_idx_x + ( (__tmp_idx_y - 1)  *  __tmp_size_x) ) ] - xi[ (0 * __DATA_NUM) + __tid ])/R:(double)0.0;
	x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 0 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 1 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 1 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 2 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 2 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 3 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 3 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 4 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 4 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 5 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 5 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 6 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 6 * __DATA_NUM )  + __tid ) ];
	x1[ (  ( 7 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 7 * __DATA_NUM )  + __tid ) ];
	y1[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  (  (  ( t >= z[4] )  &&  ( t <= z[5] )  &&  (  (  ( t - z[4] )  -  ( floor(  (  ( t - z[4] )  / z[6] )  ) * z[6] )  )  <= z[7] )  )  ? z[8] : (double)0 ) ;
	y1[ (  ( 1 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.32 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)47.13 )  )  /  ( (double)1 - exp( (  ( - (double)0.1 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)47.13 )  )  ) )  ) ;
	y1[ (  ( 2 * __DATA_NUM )  + __tid ) ] =  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] <  ( - (double)40 )  )  ?  ( (double)0.135 * exp( (  ( (double)80 + x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  /  ( - (double)6.8 )  )  ) )  : (double)0 ) ;
	y1[ (  ( 3 * __DATA_NUM )  + __tid ) ] =  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] <  ( - (double)40 )  )  ?  (  (  (  (  ( - (double)127140 )  * exp( ( (double)0.2444 * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  -  ( (double)0.00003474 * exp( (  ( - (double)0.04391 )  * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)37.78 )  )  /  ( (double)1 + exp( ( (double)0.311 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)79.23 )  )  ) )  )  : (double)0 ) ;
	y1[ (  ( 4 * __DATA_NUM )  + __tid ) ] =  ( (double)7.7 -  ( (double)13.0287 * log(  ( x1[ (  ( 7 * __DATA_NUM )  + __tid ) ] / (double)1 )  ) )  ) ;
	y1[ (  ( 5 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.095 * exp( (  ( - (double)0.01 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - (double)5 )  )  ) )  /  ( (double)1 + exp( (  ( - (double)0.072 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - (double)5 )  )  ) )  ) ;
	y1[ (  ( 6 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.012 * exp( (  ( - (double)0.008 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)28 )  )  ) )  /  ( (double)1 + exp( ( (double)0.15 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)28 )  )  ) )  ) ;
	y1[ (  ( 7 * __DATA_NUM )  + __tid ) ] =  ( (double)0.282 * sqrt(  ( z[13] / (double)5.4 )  ) ) ;
	y1[ (  ( 8 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.0005 * exp( ( (double)0.083 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)50 )  )  ) )  /  ( (double)1 + exp( ( (double)0.057 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)50 )  )  ) )  ) ;
	y1[ (  ( 9 * __DATA_NUM )  + __tid ) ] =  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] >  ( - (double)100 )  )  ?  (  ( (double)2.837 *  ( exp( ( (double)0.04 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)77 )  )  ) - (double)1 )  )  /  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)77 )  * exp( ( (double)0.04 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)35 )  )  ) )  )  : (double)1 ) ;
	y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] =  (  (  ( z[0] * z[1] )  / z[2] )  * log(  ( z[13] / z[14] )  ) ) ;
	y1[ (  ( 11 * __DATA_NUM )  + __tid ) ] =  ( (double)1.02 /  ( (double)1 + exp( ( (double)0.2385 *  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] )  - (double)59.215 )  )  ) )  ) ;
	y1[ (  ( 12 * __DATA_NUM )  + __tid ) ] = y1[ (  ( 10 * __DATA_NUM )  + __tid ) ];
	y1[ (  ( 13 * __DATA_NUM )  + __tid ) ] =  ( z[17] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - z[16] )  ) ;
	y1[ (  ( 14 * __DATA_NUM )  + __tid ) ] =  (  (  ( z[0] * z[1] )  / z[2] )  * log(  ( z[10] / z[11] )  ) ) ;
	y1[ (  ( 15 * __DATA_NUM )  + __tid ) ] =  ( (double)0.08 * exp( (  ( - x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  / (double)11 )  ) ) ;
	y1[ (  ( 16 * __DATA_NUM )  + __tid ) ] =  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] <  ( - (double)40 )  )  ?  (  ( (double)0.1212 * exp( (  ( - (double)0.01052 )  * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  /  ( (double)1 + exp( (  ( - (double)0.1378 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)40.14 )  )  ) )  )  :  (  ( (double)0.3 * exp( (  ( - (double)0.0000002535 )  * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  /  ( (double)1 + exp( (  ( - (double)0.1 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)32 )  )  ) )  )  ) ;
	y1[ (  ( 17 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.07 * exp( (  ( - (double)0.017 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)44 )  )  ) )  /  ( (double)1 + exp( ( (double)0.05 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)44 )  )  ) )  ) ;
	y1[ (  ( 18 * __DATA_NUM )  + __tid ) ] =  (  (  ( z[0] * z[1] )  / z[2] )  * log(  (  ( z[13] +  ( z[12] * z[10] )  )  /  ( z[14] +  ( z[12] * z[11] )  )  )  ) ) ;
	y1[ (  ( 19 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.0013 * exp( (  ( - (double)0.06 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)20 )  )  ) )  /  ( (double)1 + exp( (  ( - (double)0.04 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)20 )  )  ) )  ) ;
	y1[ (  ( 20 * __DATA_NUM )  + __tid ) ] =  (  (  ( (double)0.49124 * exp( ( (double)0.08032 *  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)5.476 )  - y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] )  )  ) )  +  ( (double)1 * exp( ( (double)0.06175 *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] -  ( y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] + (double)594.31 )  )  )  ) )  )  /  ( (double)1 + exp( (  ( - (double)0.5143 )  *  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] )  + (double)4.753 )  )  ) )  ) ;
	y1[ (  ( 21 * __DATA_NUM )  + __tid ) ] =  ( (double)1 /  ( (double)1 + exp( (  ( (double)7.488 - x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  / (double)5.98 )  ) )  ) ;
	y1[ (  ( 22 * __DATA_NUM )  + __tid ) ] =  ( z[9] * pow(x1[ (  ( 1 * __DATA_NUM )  + __tid ) ] , (double)3 ) * x1[ (  ( 2 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 3 * __DATA_NUM )  + __tid ) ] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 14 * __DATA_NUM )  + __tid ) ] )  ) ;
	y1[ (  ( 23 * __DATA_NUM )  + __tid ) ] =  ( (double)0.09 * x1[ (  ( 4 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 5 * __DATA_NUM )  + __tid ) ] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 4 * __DATA_NUM )  + __tid ) ] )  ) ;
	y1[ (  ( 24 * __DATA_NUM )  + __tid ) ] =  ( y1[ (  ( 7 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 6 * __DATA_NUM )  + __tid ) ] * y1[ (  ( 9 * __DATA_NUM )  + __tid ) ] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 18 * __DATA_NUM )  + __tid ) ] )  ) ;
	y1[ (  ( 25 * __DATA_NUM )  + __tid ) ] =  ( y1[ (  ( 11 * __DATA_NUM )  + __tid ) ] /  ( y1[ (  ( 11 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 20 * __DATA_NUM )  + __tid ) ] )  ) ;
	y1[ (  ( 26 * __DATA_NUM )  + __tid ) ] =  (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] <  ( - (double)40 )  )  ?  (  ( (double)3.56 * exp( ( (double)0.079 * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  +  ( (double)310000 * exp( ( (double)0.35 * x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  ) )  )  :  ( (double)1 /  ( (double)0.13 *  ( (double)1 + exp( (  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)10.66 )  /  ( - (double)11.1 )  )  ) )  )  )  ) ;
	y1[ (  ( 27 * __DATA_NUM )  + __tid ) ] =  ( (double)0.6047 * sqrt(  ( z[13] / (double)5.4 )  ) ) ;
	y1[ (  ( 28 * __DATA_NUM )  + __tid ) ] =  ( z[15] * y1[ (  ( 21 * __DATA_NUM )  + __tid ) ] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 12 * __DATA_NUM )  + __tid ) ] )  ) ;
	y1[ (  ( 29 * __DATA_NUM )  + __tid ) ] =  (  ( (double)0.0065 * exp( (  ( - (double)0.02 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)30 )  )  ) )  /  ( (double)1 + exp( (  ( - (double)0.2 )  *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + (double)30 )  )  ) )  ) ;
	y1[ (  ( 30 * __DATA_NUM )  + __tid ) ] =  ( y1[ (  ( 27 * __DATA_NUM )  + __tid ) ] * y1[ (  ( 25 * __DATA_NUM )  + __tid ) ] *  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] - y1[ (  ( 10 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  (  (  ( - (double)1 )  / z[3] )  *  ( y1[ (  ( 0 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 22 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 23 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 24 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 30 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 28 * __DATA_NUM )  + __tid ) ] + y1[ (  ( 13 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 1 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 1 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 1 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 15 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 1 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 2 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 2 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 2 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 26 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 2 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 3 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 3 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 3 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 16 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 3 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 4 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 5 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 4 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 17 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 4 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 5 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 6 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 5 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 29 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 5 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 6 * __DATA_NUM )  + __tid ) ] =  (  ( y1[ (  ( 8 * __DATA_NUM )  + __tid ) ] *  ( (double)1 - x1[ (  ( 6 * __DATA_NUM )  + __tid ) ] )  )  -  ( y1[ (  ( 19 * __DATA_NUM )  + __tid ) ] * x1[ (  ( 6 * __DATA_NUM )  + __tid ) ] )  ) ;
	k1[ (  ( 7 * __DATA_NUM )  + __tid ) ] =  (  (  (  ( - (double)0.0001 )  / (double)1 )  * y1[ (  ( 23 * __DATA_NUM )  + __tid ) ] )  +  ( (double)0.07 *  ( (double)0.0001 - x1[ (  ( 7 * __DATA_NUM )  + __tid ) ] )  )  ) ;
	x2[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 1 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 1 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 1 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 2 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 2 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 2 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 3 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 3 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 3 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 4 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 4 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 4 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 5 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 5 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 5 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 6 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 6 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 6 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	x2[ (  ( 7 * __DATA_NUM )  + __tid ) ] =  ( x1[ (  ( 7 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 7 * __DATA_NUM )  + __tid ) ] * d )  ) ;
	xo[ (  ( 0 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 0 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 1 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 1 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 2 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 2 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 3 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 3 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 4 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 4 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 5 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 5 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 6 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 6 * __DATA_NUM )  + __tid ) ];
	xo[ (  ( 7 * __DATA_NUM )  + __tid ) ] = x2[ (  ( 7 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 0 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 0 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 1 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 1 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 2 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 2 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 3 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 3 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 4 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 4 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 5 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 5 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 6 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 6 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 7 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 7 * __DATA_NUM )  + __tid ) ];
}



