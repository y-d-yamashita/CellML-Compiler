#include<stdio.h>
#include<math.h>
#include<cutil.h>
#include<cuda.h>
#define __DATA_NUM 32
#define __DATA_NUMX 32
#define __DATA_NUMY 1
#define __THREADS_X 256
#define __THREADS_Y 1
#define __THREADS_Z 1
#define __BLOCKS_X ( __DATA_NUM /  ( __THREADS_X * __THREADS_Y * __THREADS_Z ) ) 
#define __BLOCKS_Y 1


int main ( int argc , char** argv ) ;
__global__ void __init_kernel ( double* xi ) ;
__global__ void __calc_kernel ( double* xi , double* xo , double* x0 , double* x1 , double* x2 , double* x3 , double* k1 , double* k2 , double* k3 , double* y0 , double* y1 , double* y2 , double* z , double t , double d , double R ) ;

int main ( int argc , char** argv ) {

	double* __host_xi;
	double* __dev_xi;
	double* __host_xo;
	double* __dev_xo;
	double* __host_x0;
	double* __dev_x0;
	double* __host_x1;
	double* __dev_x1;
	double* __host_x2;
	double* __dev_x2;
	double* __host_x3;
	double* __dev_x3;
	double* __host_k1;
	double* __dev_k1;
	double* __host_k2;
	double* __dev_k2;
	double* __host_k3;
	double* __dev_k3;
	double* __host_y0;
	double* __dev_y0;
	double* __host_y1;
	double* __dev_y1;
	double* __host_y2;
	double* __dev_y2;
	double* __host_z;
	double* __dev_z;
	double t;
	double d = 0.010000;
	dim3 __block ( __THREADS_X , __THREADS_Y , __THREADS_Z ) ;
	dim3 __grid ( __BLOCKS_X , __BLOCKS_Y ) ;

	CUT_DEVICE_INIT ( argc , argv ) ; 
	__host_xi = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_xo = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_x0 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_x1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_x2 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_x3 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_k1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_k2 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_k3 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; ;
	__host_y0 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; ;
	__host_y1 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; ;
	__host_y2 = (double*)malloc (  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; ;
	__host_z = (double*)malloc (  ( sizeof( double ) * 0 )  ) ; ;
	memset ( __host_xi , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_xo , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_x0 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_x1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_x2 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_x3 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_k1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_k2 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_k3 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	memset ( __host_y0 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	memset ( __host_y1 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	memset ( __host_y2 , 0 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	memset ( __host_z , 0 ,  ( sizeof( double ) * 0 )  ) ; 
	cudaMalloc ( ( void** ) &__dev_xi ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_xo ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x1 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x2 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_x3 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_k1 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_k2 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_k3 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_y0 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_y1 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_y2 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  ) ; 
	cudaMalloc ( ( void** ) &__dev_z ,  ( sizeof( double ) * 0 )  ) ; 
	cudaMemcpy ( __dev_xi , __host_xi ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_xo , __host_xo ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x0 , __host_x0 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x1 , __host_x1 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x2 , __host_x2 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_x3 , __host_x3 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_k1 , __host_k1 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_k2 , __host_k2 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_k3 , __host_k3 ,  ( sizeof( double ) *  ( __DATA_NUM * 1 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_y0 , __host_y0 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_y1 , __host_y1 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_y2 , __host_y2 ,  ( sizeof( double ) *  ( __DATA_NUM * 0 )  )  , cudaMemcpyHostToDevice ) ; 
	cudaMemcpy ( __dev_z , __host_z ,  ( sizeof( double ) * 0 )  , cudaMemcpyHostToDevice ) ; 
	__init_kernel <<< __grid , __block >>>  ( __dev_xi ) ; 
	for(t = 0.000000; ( t <= 400.000000 ) ;t =  ( t + d ) ){

		for(ix = 0; ( ix < __DATA_NUMX ) ;ix++){

			for(iy = 0; ( iy < __DATA_NUMY ) ;iy++){

				__calc_kernel <<< __grid , __block >>>  ( __dev_xi , __dev_xo , __dev_x0 , __dev_x1 , __dev_x2 , __dev_x3 , __dev_k1 , __dev_k2 , __dev_k3 , __dev_y0 , __dev_y1 , __dev_y2 , __dev_z , t , d ) ; 

			}


		}


	}

	free ( __host_xi ) ; 
	free ( __host_xo ) ; 
	free ( __host_x0 ) ; 
	free ( __host_x1 ) ; 
	free ( __host_x2 ) ; 
	free ( __host_x3 ) ; 
	free ( __host_k1 ) ; 
	free ( __host_k2 ) ; 
	free ( __host_k3 ) ; 
	free ( __host_y0 ) ; 
	free ( __host_y1 ) ; 
	free ( __host_y2 ) ; 
	free ( __host_z ) ; 
	cudaFree ( __dev_xi ) ; 
	cudaFree ( __dev_xo ) ; 
	cudaFree ( __dev_x0 ) ; 
	cudaFree ( __dev_x1 ) ; 
	cudaFree ( __dev_x2 ) ; 
	cudaFree ( __dev_x3 ) ; 
	cudaFree ( __dev_k1 ) ; 
	cudaFree ( __dev_k2 ) ; 
	cudaFree ( __dev_k3 ) ; 
	cudaFree ( __dev_y0 ) ; 
	cudaFree ( __dev_y1 ) ; 
	cudaFree ( __dev_y2 ) ; 
	cudaFree ( __dev_z ) ; 
	CUT_EXIT ( argc , argv ) ; 
}


__global__ void __init_kernel ( double* xi ) {

	const unsigned int __tmp_idx_x =  ( threadIdx.x +  ( blockDim.x * blockIdx.x )  ) ;
	const unsigned int __tmp_idx_y =  ( threadIdx.y +  ( blockDim.y * blockIdx.y )  ) ;
	const unsigned int __tmp_size_x =  ( blockDim.x * gridDim.x ) ;
	const unsigned int __tid =  ( __tmp_idx_x +  ( __tmp_idx_y * __tmp_size_x )  ) ;

}


__global__ void __calc_kernel ( double* xi , double* xo , double* x0 , double* x1 , double* x2 , double* x3 , double* k1 , double* k2 , double* k3 , double* y0 , double* y1 , double* y2 , double* z , double t , double d , double R ) {

	const unsigned int __tmp_idx_x =  ( threadIdx.x +  ( blockDim.x * blockIdx.x )  ) ;
	const unsigned int __tmp_idx_y =  ( threadIdx.y +  ( blockDim.y * blockIdx.y )  ) ;
	const unsigned int __tmp_size_x =  ( blockDim.x * gridDim.x ) ;
	const unsigned int __tid =  ( __tmp_idx_x +  ( __tmp_idx_y * __tmp_size_x )  ) ;
	double ym;

	ym = (__tmp_idx_y!=0)?(xi[ (0 * __DATA_NUM) + (__tmp_idx_x + ( (__tmp_idx_y - 1)  *  __tmp_size_x) ) ] - xi[ (0 * __DATA_NUM) + __tid ])/R:(double)0.0;
	x0[ (  ( 0 * __DATA_NUM )  + __tid ) ] = xi[ (  ( 0 * __DATA_NUM )  + __tid ) ];
	k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] = exp(t );
	x1[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  ( x0[ (  ( 0 * __DATA_NUM )  + __tid ) ] +  ( k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] *  ( d / (double)2 )  )  ) ;
	k2[ (  ( 0 * __DATA_NUM )  + __tid ) ] = exp( ( t +  ( d / (double)2 )  )  );
	x2[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  ( x0[ (  ( 0 * __DATA_NUM )  + __tid ) ] +  ( d *  (  ( - k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  +  ( (double)2 * k2[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  )  )  ) ;
	k3[ (  ( 0 * __DATA_NUM )  + __tid ) ] = exp( ( t + d )  );
	x3[ (  ( 0 * __DATA_NUM )  + __tid ) ] =  ( x0[ (  ( 0 * __DATA_NUM )  + __tid ) ] +  (  ( d / (double)6 )  *  ( k1[ (  ( 0 * __DATA_NUM )  + __tid ) ] +  ( (double)4 * k2[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  + k3[ (  ( 0 * __DATA_NUM )  + __tid ) ] )  )  ) ;
	xo[ (  ( 0 * __DATA_NUM )  + __tid ) ] = x3[ (  ( 0 * __DATA_NUM )  + __tid ) ];
	xi[ (  ( 0 * __DATA_NUM )  + __tid ) ] = xo[ (  ( 0 * __DATA_NUM )  + __tid ) ];
}



